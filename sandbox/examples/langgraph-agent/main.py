import os
import json
from typing import List, Dict, Any, TypedDict, Annotated, Union, Optional
from dataclasses import dataclass, field
from enum import Enum
from dotenv import load_dotenv
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from agent_sandbox import Sandbox

load_dotenv()


class AgentState(TypedDict):
    messages: List[BaseMessage]
    current_step: str
    tool_calls: List[Dict[str, Any]]
    tool_results: List[Dict[str, Any]]
    final_answer: str
    iterations: int


class AgentStep(Enum):
    UNDERSTAND = "understand"
    PLAN = "plan"
    EXECUTE = "execute"
    REVIEW = "review"
    ANSWER = "answer"


class SandboxClient:
    def __init__(self):
        self.sandbox_url = os.getenv("SANDBOX_BASE_URL", "http://localhost:8080")
        self._sandbox = None
    
    @property
    def sandbox(self) -> Sandbox:
        if self._sandbox is None:
            self._sandbox = Sandbox(base_url=self.sandbox_url)
        return self._sandbox


sandbox_client = SandboxClient()


@tool
def execute_python_code(code: str) -> str:
    """Execute Python code in the sandbox environment."""
    result = sandbox_client.sandbox.jupyter.execute_code(code=code)
    
    if hasattr(result, 'data') and result.data:
        outputs = result.data.outputs
        if outputs:
            output_texts = []
            for output in outputs:
                if hasattr(output, 'text') and output.text:
                    output_texts.append(output.text)
                elif hasattr(output, 'error') and output.error:
                    output_texts.append(f"Error: {output.error}")
            return "\n".join(output_texts) if output_texts else "Code executed successfully (no output)"
    
    return "Code executed successfully"


@tool
def execute_javascript_code(code: str) -> str:
    """Execute JavaScript/Node.js code in the sandbox environment."""
    result = sandbox_client.sandbox.nodejs.execute_code(code=code)
    
    if hasattr(result, 'data') and result.data:
        outputs = result.data.outputs
        if outputs:
            output_texts = []
            for output in outputs:
                if hasattr(output, 'text') and output.text:
                    output_texts.append(output.text)
                elif hasattr(output, 'error') and output.error:
                    output_texts.append(f"Error: {output.error}")
            return "\n".join(output_texts) if output_texts else "Code executed successfully (no output)"
    
    return "Code executed successfully"


@tool
def read_file(file_path: str) -> str:
    """Read the contents of a file from the sandbox."""
    result = sandbox_client.sandbox.file.read_file(path=file_path)
    
    if hasattr(result, 'data') and result.data:
        return result.data.content
    
    return "File not found or empty"


@tool
def write_file(file_path: str, content: str) -> str:
    """Write content to a file in the sandbox."""
    result = sandbox_client.sandbox.file.write_file(path=file_path, content=content)
    
    if hasattr(result, 'data') and result.data:
        return f"Successfully wrote to {file_path}"
    
    return "Failed to write file"


@tool
def list_files(directory: str = "/tmp") -> str:
    """List files in a directory of the sandbox."""
    result = sandbox_client.sandbox.file.list_path(path=directory)
    
    if hasattr(result, 'data') and result.data:
        files = result.data.files
        if files:
            file_list = [f"{f.name} ({f.type})" for f in files]
            return "\n".join(file_list)
    
    return "Directory not found or empty"


@tool
def search_files(pattern: str, path: str = "/tmp") -> str:
    """Search for files matching a pattern in the sandbox."""
    result = sandbox_client.sandbox.file.find_files(path=path, pattern=pattern)
    
    if hasattr(result, 'data') and result.data:
        files = result.data.files
        if files:
            file_list = [f"{f.name} ({f.type})" for f in files]
            return "\n".join(file_list)
    
    return "No files found matching the pattern"


tools = [
    execute_python_code,
    execute_javascript_code,
    read_file,
    write_file,
    list_files,
    search_files,
]

tool_node = ToolNode(tools)


def create_llm():
    """Create LLM instance using Volcengine API."""
    api_key = os.getenv("COZE_WORKLOAD_IDENTITY_API_KEY")
    base_url = os.getenv("COZE_INTEGRATION_MODEL_BASE_URL")
    model = os.getenv("CODE_LLM_MODEL", "deepseek-v3-2-251201")
    
    if not api_key or not base_url:
        raise ValueError("Missing required environment variables: COZE_WORKLOAD_IDENTITY_API_KEY or COZE_INTEGRATION_MODEL_BASE_URL")
    
    return ChatOpenAI(
        model=model,
        base_url=base_url,
        api_key=api_key,
        temperature=0,
    )


def should_continue(state: AgentState) -> str:
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­æ‰§è¡Œæˆ–ç»“æŸ"""
    messages = state.get("messages", [])
    last_message = messages[-1] if messages else None
    
    if last_message and isinstance(last_message, AIMessage):
        if last_message.content.strip().endswith("FINAL_ANSWER:"):
            return "end"
        elif any(isinstance(msg, ToolMessage) for msg in messages):
            return "continue"
    
    return "continue"


def understand_node(state: AgentState) -> AgentState:
    """ç†è§£ç”¨æˆ·è¾“å…¥çš„èŠ‚ç‚¹"""
    llm = create_llm()
    messages = state["messages"]
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚ä½ éœ€è¦ç†è§£ç”¨æˆ·çš„é—®é¢˜ï¼Œå¹¶å†³å®šæ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·ã€‚

è¯·åˆ†æç”¨æˆ·çš„é—®é¢˜ï¼š
1. é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ
2. éœ€è¦æ‰§è¡Œä»€ä¹ˆæ“ä½œï¼Ÿ
3. éœ€è¦ä½¿ç”¨å“ªäº›å·¥å…·ï¼Ÿ

è¯·ç”¨ç®€æ´çš„è¯­è¨€å›ç­”ã€‚"""
    
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        *messages
    ])
    
    return {
        "messages": state["messages"] + [response],
        "current_step": AgentStep.PLAN.value,
        "tool_calls": state.get("tool_calls", []),
        "tool_results": state.get("tool_results", []),
        "final_answer": "",
        "iterations": state.get("iterations", 0) + 1
    }


def plan_node(state: AgentState) -> AgentState:
    """è§„åˆ’æ‰§è¡Œæ­¥éª¤çš„èŠ‚ç‚¹"""
    llm = create_llm()
    messages = state["messages"]
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚åŸºäºå½“å‰çš„é—®é¢˜å’Œå·²æœ‰çš„ä¿¡æ¯ï¼Œè§„åˆ’ä¸‹ä¸€æ­¥éœ€è¦åšä»€ä¹ˆã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
PLANNED_ACTION: <ä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ>
USE_TOOL: <æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…· (yes/no)>
TOOL_NAME: <å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œå·¥å…·åç§°>
TOOL_ARGS: <å·¥å…·å‚æ•°ï¼ŒJSONæ ¼å¼>

å¦‚æœé—®é¢˜å·²ç»è§£å†³ï¼Œè¯·å›ç­”ï¼š
FINAL_ANSWER: <æœ€ç»ˆç­”æ¡ˆ>"""
    
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        *messages
    ])
    
    return {
        "messages": state["messages"] + [response],
        "current_step": AgentStep.EXECUTE.value,
        "tool_calls": state.get("tool_calls", []),
        "tool_results": state.get("tool_results", []),
        "final_answer": "",
        "iterations": state.get("iterations", 0)
    }


def execute_node(state: AgentState) -> AgentState:
    """æ‰§è¡Œå·¥å…·è°ƒç”¨çš„èŠ‚ç‚¹"""
    messages = state["messages"]
    last_message = messages[-1] if messages else None
    
    if last_message and isinstance(last_message, AIMessage):
        if "FINAL_ANSWER:" in last_message.content:
            answer = last_message.content.replace("FINAL_ANSWER:", "").strip()
            return {
                "messages": state["messages"],
                "current_step": AgentStep.ANSWER.value,
                "tool_calls": state.get("tool_calls", []),
                "tool_results": state.get("tool_results", []),
                "final_answer": answer,
                "iterations": state.get("iterations", 0)
            }
    
    return state


def review_node(state: AgentState) -> AgentState:
    """å®¡æŸ¥ç»“æœçš„èŠ‚ç‚¹"""
    llm = create_llm()
    messages = state["messages"]
    tool_results = state.get("tool_results", [])
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚è¯·å®¡æŸ¥å·¥å…·æ‰§è¡Œçš„ç»“æœï¼Œåˆ¤æ–­æ˜¯å¦å®Œæˆäº†ä»»åŠ¡ã€‚

å¦‚æœä»»åŠ¡å®Œæˆï¼Œè¯·å›ç­”ï¼š
FINAL_ANSWER: <æœ€ç»ˆç­”æ¡ˆ>

å¦‚æœä»»åŠ¡æœªå®Œæˆï¼Œè¯·ç»§ç»­è§„åˆ’ä¸‹ä¸€æ­¥æ“ä½œã€‚"""
    
    response = llm.invoke([
        SystemMessage(content=system_prompt),
        *messages,
        SystemMessage(content=f"\nå·¥å…·æ‰§è¡Œç»“æœ: {tool_results}")
    ])
    
    return {
        "messages": state["messages"] + [response],
        "current_step": AgentStep.PLAN.value,
        "tool_calls": state.get("tool_calls", []),
        "tool_results": state.get("tool_results", []),
        "final_answer": "",
        "iterations": state.get("iterations", 0)
    }


def create_agent_graph() -> StateGraph:
    """åˆ›å»º LangGraph çŠ¶æ€å›¾"""
    workflow = StateGraph(AgentState)
    
    workflow.add_node("understand", understand_node)
    workflow.add_node("plan", plan_node)
    workflow.add_node("execute", execute_node)
    workflow.add_node("review", review_node)
    workflow.add_node("tools", tool_node)
    
    workflow.set_entry_point("understand")
    
    workflow.add_edge("understand", "plan")
    workflow.add_edge("plan", "execute")
    
    workflow.add_conditional_edges(
        "execute",
        lambda state: should_continue(state),
        {
            "continue": "tools",
            "end": END
        }
    )
    
    workflow.add_edge("tools", "review")
    workflow.add_edge("review", "plan")
    
    return workflow


def run_graph(query: str) -> Dict[str, Any]:
    """è¿è¡Œå›¾æ¨ç†"""
    app = create_agent_graph().compile()
    
    initial_state: AgentState = {
        "messages": [HumanMessage(content=query)],
        "current_step": AgentStep.UNDERSTAND.value,
        "tool_calls": [],
        "tool_results": [],
        "final_answer": "",
        "iterations": 0
    }
    
    config = {"configurable": {"thread_id": "1"}}
    
    final_state = None
    for state in app.stream(initial_state, config=config):
        final_state = state
        print(f"\nğŸ“ çŠ¶æ€æ›´æ–°: {list(state.keys())}")
    
    return final_state


def main():
    """ä¸»å…¥å£"""
    print("ğŸš€ å¯åŠ¨ LangGraph Agent...")
    print("=" * 50)
    print("ğŸ’¡ åŸºäºå·¥ä½œæµçš„æ™ºèƒ½ä»£ç†")
    print("=" * 50)
    
    print("\nğŸ’¬ Agent å·²å°±ç»ªï¼Œè¯·è¾“å…¥æ‚¨çš„é—®é¢˜:")
    print("   (ç¤ºä¾‹: è®¡ç®— 1+1, åˆ—å‡º /tmp ç›®å½•, ç­‰)")
    print("   è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("-" * 50)
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ æ‚¨: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            if not user_input:
                continue
            
            print("\nğŸ¤– æ‰§è¡Œä¸­...")
            result = run_graph(user_input)
            
            print("\nâœ… æœ€ç»ˆç»“æœ:")
            print("-" * 50)
            if result and "final_answer" in result:
                print(result["final_answer"])
            print("-" * 50)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()
